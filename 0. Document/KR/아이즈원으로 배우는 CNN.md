**작성중**
# 아이즈원으로 배우는 CNN (조유리즈 구별기)

## 0. 큰 그림부터 보자

아직 CNN이 무엇인지 그리고 어떻게 구성되어 동작이 되는지 아는게 없지만, 블랙박스 관점에서 생각을 해봅시다.

[사진] -> [뭔진 모르겠지만 암튼 CNN] -> [조유리? 김채원? 최예나?]

실제 CNN의 구조는 다음과 같습니다
[영어로 써있어서 보기 무서운 CNN 이미지]

대략적으로 무언가의 절차를 밟아가며 학습을 한다는 점만 인지하고 자세한 내용은 아래에서 다루도록 하겠습니다.

## 1. 사람의 관점에서 바라보자

### 학습 과정에 대하여

사람을 구별하는 과정을 한번 떠올려 봅시다. 어떤 절차를 통해 생각을 하게 될까요?
모든 사람들이 다 같은 과정을 거치지는 않지만, 다음과 같은 큰 흐름은 유사할 것입니다.

1. 전체 사진에서 사람의 얼굴을 찾습니다.
2. 얼굴에서 고유한 특징을 찾습니다. (ex. 쌍커풀의 유무, 콧구멍의 크기, 얼굴의 형태 등)
3. 2에서 얻은 정보를 취합하여 특징에 맞는 사람들의 후보 중 가장 가까운 사람을 고릅니다.

사람의 얼굴을 구별하는 작업은 단순한듯 하지만 나름대로 절차적인 과정을 통해 진행이 됩니다. 인간에게는 무의식에 가까운 일이지만 왜 다음과 같은 과정을 거치는지 다시 한번 곰곰히 생각해 봅시다.

    1. 전체적인 사진에서 사람의 얼굴을 찾는다.

    얼굴은 옷이나 머리카락의 모양, 색상에 비해 크게 변하지 않는 특징입니다. 만약 옷의 색상을 이용해 학습을 했다고 생각을 해봅시다.

    다음과 같이 노란색 옷을 입은 사람을 김채원이라고 학습을 했다 가정했을 때,

    [Eyes on me 김채원 so curious 무대 사진]

    노란색 옷을 입고 있고있는 이 사진도 김채원이라고 할 수 있을까요?

    [Eyes on me 최예나 so curious 무대 사진]

    위와 같이 자주 변하거나 공통적으로 발견되는 정보는 분류 학습을 하는데 있어서 방해가 되는 정보입니다. 따라서 학습을 진행하기 전에 불필요한 정보를 사전에 차단하고(전처리) 학습을 진행해야 학습효율이 더 높게 나타납니다.


    2. 얼굴에서 고유한 특징을 찾는다.

    {아이돌룸 조유리즈 구별법 사진}

    전처리를 거친 얼굴사진에도 사람의 특징을 구별하는데 중요한 정보와 크게 중요하지 않은 정보가 있습니다. 극단적인 예시로 아래의 확대한 사진만을 보고 사람을 구별해 봅시다.

    [확대한 조유리의 볼] vs [확대한 김채원의 볼]

    [확대한 김채원의 입] vs [확대한 최예나의 입]

    > (TMI : 김채원의 입술에는 강아지에게 긁힌 흉터가 있고, 최예나는 부리같은 입술을 가지고 있어 오리라는 별명을 가지고 있습니다.)

    두 가지 경우를 비교했을 때 전자에 비해 후자가 구별하는데 더 영향력이 있는 정보라고 할 수 있습니다.

    그렇다면 어떻게 하면 전처리 단계 처럼 특징있는 부분만을 딱 뽑아서 학습을 할 수 있을까요?
    고전적인 컴퓨터 비전 알고리즘(해리스 코너, 소벨엣지, SURF 등)을 이용해 특징을 추출한다고 해도 원하는 특징만 고르는데는 큰 어려움이 있습니다. 따라서 이런 부분은 전처리를 통해 해결하기에는 어렵고 신경망을 통해서 처리해야 합니다. 신경망이 어떤 방식으로 동작 하는지는 아래에서 좀 더 자세하게 알아보겠습니다.


    3. 특징에 맞는 사람들의 후보 중 가장 가까운 사람을 고른다.

    학습을 통해 특징들을 모은 뒤, 마지막으로 사람을 분류하는 추론작업을 진행해야 합니다.
    다음과 같은 특징이 적힌 밴 다이어그램과 인물 사진을 보고 사람을 예측을 해봅시다.

    - 조유리 : 볼살이 있는 얼굴, 쌍커풀, 콧등의 점, 날렵한 코  etc
    - 김채원 : 동그란 얼굴, 입술의 흉터, 이마의 점, 쌍커풀, etc
    - 최예나 : 오리 입술, 장난기있는 눈매, 쌍커풀, etc

    [애매한 조유리 사진]

    이 사진이 [쌍커풀], [볼살이 있는 얼굴], [장난기 있는 눈매], [콧등의 점]과 [날렵한 코]라는 특징이 있다고 할 때,
    위에 제시된 명제만 가지고 판단하면 조유리의 확률이 57%, 최예나일 확률이 29%, 김채원일 확률이 14%라고 할 수 있습니다.
    예시로는 추상적인 형태를 들었지만 실제 신경망에서는 컨볼루션과 활성화함수 그리고 폴링계층 등을 거쳐서 나온 결과를 분류함수에 넣어 판단을 합니다.

전체적인 과정을 이제 딥러닝에 사용되는 용어로 바꿔서 표현해 볼까요?

전처리(사람의 얼굴 추출) -> 합성곱, 폴링, 드롭아웃(얼굴의 고유한 특징 찾기) -> 소프트맥스(가장 높은 확률의 후보 고르기)

처음에 나왔던 CNN구조의 사진과 비교하면 깊이는 다르지만 인간의 판단과 CNN이 유사한 형태를 띄는 것을 확인할 수 있습니다.


### 학습 방법에 대하여

이번에는 수학 성적 향상을 위해 문제집을 푼다고 가정을 하고 우리가 어떤 방식으로 공부를 하는지 생각해 봅시다.

    1. 문제지와 답안지
    문제를 풀었을 때 문제의 답이 맞는지 틀린지 채점을 하여 학습 효율(점수)을 계산하게 됩니다. 그리고 얼마나 정답과 동떨어진 답안을 작성했는지 확인을 할 수 있습니다.

    2. 복습
    풀이했던 문제집을 반복하여 학습의 효율을 높입니다.

    3. 반복 및 문제 묶음
    한 문제집을 몇번을 반복해서 풀이를 할지, 그리고 몇 문제를 풀고 나서 답안지를 확인 할 지 결정을 합니다.

신경망에서도 다음과 같은 요소를 고려하며 훈련과 평가를 진행하게 됩니다. 
놀랍게도 학습의 효율은 인간의 공부와 비슷한 성질을 가지고 있습니다. 공부를 할 때 답안지를 확인하지 않거나 지나치게 답안지에 의존하면 실전에서 예상치 못한 결과를 맞이하기도 하고(언더피팅, 오버피팅), 매 문제마다 답안지를 확인하면 공부를 하는데 속도가 느려지는 등 같은 신경망과 학습 데이터가 주어져도 학습 방법에 따라 결과는 달라지게 됩니다.


## 2. 딥러닝의 관점에서 바라보자

### 학습 과정에 대하여

1. 신경망의 구조와 동작 방식

2. 활성화 함수

2. 정확도와 손실함수

acc와 loss의 의미, 왜 선형으로 하면 loss가 의미가 없는지, 그라디언트 디센트

3. 오차 역전파

위에서 구한 loss를 어떻게 피드백을 주는지, 미분==변화량 : 내가 너때문에 이렇게 변해버렸다~

3. Affine계층과 컨볼루션 레이어

4. softmax함수

### 학습 방법에 대하여

1. 훈련 데이터셋과 검증 데이터셋

train-test split, 

6. 언더피팅과 오버피팅

정의 선형분류 예시로 들어도 될듯

5. 배치사이즈와 에포크

정의, 당연한건데 설명을 어떻게 해야할지 모르겠다
